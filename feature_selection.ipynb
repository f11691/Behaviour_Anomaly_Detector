{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "65SQNsbekm3u"
   },
   "source": [
    "# Create the Fetures Group from PCAPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4PO8HXtPGbsG",
    "outputId": "7fed5ba7-1ea5-4e6b-bb05-18622ea0e72a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installation of wget\n",
      "\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/PyYAML-6.0.1.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/six-1.16.0-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/Pygments-2.16.1.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/PyYAML-6.0.1.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/six-1.16.0-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/Pygments-2.16.1.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/packaging-23.2.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/certifi-2023.7.22-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/cffi-1.16.0.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/cffi-1.15.1-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting wget\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: wget\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=8e1169c6495d748062feda429ec868892c3a4e54dbf87bd4fbb47d6094ea6dd7\n",
      "  Stored in directory: /Users/theoleyre/Library/Caches/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
      "Successfully built wget\n",
      "\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/PyYAML-6.0.1.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/six-1.16.0-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/Pygments-2.16.1.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/packaging-23.2.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/certifi-2023.7.22-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/cffi-1.16.0.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/cffi-1.15.1-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: wget\n",
      "\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/PyYAML-6.0.1.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/six-1.16.0-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/Pygments-2.16.1.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/packaging-23.2.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/certifi-2023.7.22-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/cffi-1.16.0.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/cffi-1.15.1-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed wget-3.2\n",
      "\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/PyYAML-6.0.1.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/six-1.16.0-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/Pygments-2.16.1.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/PyYAML-6.0.1.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/six-1.16.0-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/Pygments-2.16.1.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/packaging-23.2.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/certifi-2023.7.22-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/cffi-1.16.0.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/cffi-1.15.1-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/PyYAML-6.0.1.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/six-1.16.0-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/Pygments-2.16.1.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/packaging-23.2.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/certifi-2023.7.22-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/cffi-1.16.0.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/cffi-1.15.1-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "\n",
    "# scapy verification\n",
    "try:\n",
    "    import scapy\n",
    "except ImportError:\n",
    "    print(\"Installation of scapy\")\n",
    "    !pip install scapy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scapy.all import *\n",
    "from datetime import datetime\n",
    "import string\n",
    "import re\n",
    "\n",
    "# wget package\n",
    "try:\n",
    "    import wget\n",
    "except ImportError:\n",
    "    print(\"Installation of wget\")\n",
    "    !pip install wget\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5liLul09HAzB"
   },
   "source": [
    "**Load PCAP Data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "fNsEd6NHGgnb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ko\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'wget' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(filepath) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mko\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m     \u001b[43mwget\u001b[49m\u001b[38;5;241m.\u001b[39mdownload(url, bar\u001b[38;5;241m=\u001b[39mbar_thermometer)\n\u001b[1;32m      8\u001b[0m packets \u001b[38;5;241m=\u001b[39m rdpcap(filepath)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of packets in test load: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(packets)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'wget' is not defined"
     ]
    }
   ],
   "source": [
    "def load_pcap_data(filepath):\n",
    "\n",
    "    packets = rdpcap(filepath)\n",
    "    print(f\"Number of packets in test load: {len(packets)}\")\n",
    "    if packets:\n",
    "        print(packets[0].summary())\n",
    "    return packets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FvLoiJoxHGBn"
   },
   "source": [
    "**Extract Network Traffic Features:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "cgcjcfuJGk7V"
   },
   "outputs": [],
   "source": [
    "def extract_network_traffic_features(packets):\n",
    "    network_traffic_features = []\n",
    "\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    for packet in packets:\n",
    "        # Initialize variables for each feature\n",
    "        eth_src = None\n",
    "        eth_dst = None\n",
    "        src_ip = None\n",
    "        dst_ip = None\n",
    "        src_port = None\n",
    "        dst_port = None\n",
    "        protocol = None\n",
    "        timestamp = packet.time\n",
    "\n",
    "        # Extract Ethernet frame information\n",
    "        if Ether in packet:\n",
    "            eth_src = packet[Ether].src\n",
    "            eth_dst = packet[Ether].dst\n",
    "\n",
    "        # Extract IP packet information\n",
    "        if IP in packet:\n",
    "            src_ip = packet[IP].src\n",
    "            dst_ip = packet[IP].dst\n",
    "\n",
    "            if TCP in packet:\n",
    "                src_port = packet[TCP].sport\n",
    "                dst_port = packet[TCP].dport\n",
    "                protocol = 'TCP'\n",
    "            elif UDP in packet:\n",
    "                src_port = packet[UDP].sport\n",
    "                dst_port = packet[UDP].dport\n",
    "                protocol = 'UDP'\n",
    "            else:\n",
    "                # Handle other IP protocols as needed\n",
    "                protocol = packet[IP].proto\n",
    "\n",
    "        # Append extracted features as a dictionary to the network_traffic_features list\n",
    "        network_traffic_features.append({\n",
    "            'eth_src': eth_src,\n",
    "            'eth_dst': eth_dst,\n",
    "            'src_ip': src_ip,\n",
    "            'dst_ip': dst_ip,\n",
    "            'src_port': src_port,\n",
    "            'dst_port': dst_port,\n",
    "            'protocol': protocol,\n",
    "            'timestamp': timestamp\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(network_traffic_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yi8IhUo8HLDB"
   },
   "source": [
    " **Extract Session-related Information Features:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0Ix72YBhHPbL"
   },
   "outputs": [],
   "source": [
    "def extract_session_behavior_features(packets):\n",
    "    session_behaviour_features = []\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from datetime import datetime\n",
    "    from scapy.all import Ether, IP\n",
    "\n",
    "    current_session_start_time = None\n",
    "    current_session_end_time = None\n",
    "    session_start_time = None\n",
    "    failed_login_count = 0\n",
    "    session_behaviour_features = []\n",
    "    session_timestamps = []\n",
    "\n",
    "    # Define a pattern to identify authentication-related events\n",
    "    auth_event_pattern = \"authentication_failed\"\n",
    "\n",
    "    # Iterate through the packets and extract the features\n",
    "    for packet in packets:\n",
    "        # Extract Ethernet frame information\n",
    "        if Ether in packet:\n",
    "            eth_src = packet[Ether].src\n",
    "            eth_dst = packet[Ether].dst\n",
    "\n",
    "        # Extract IP packet information\n",
    "        if IP in packet:\n",
    "            # Update session start and end times\n",
    "            if current_session_start_time is None:\n",
    "                current_session_start_time = packet.time\n",
    "                # Convert packet.time to float\n",
    "                timestamp = datetime.utcfromtimestamp(float(packet.time)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "                session_timestamps.append(timestamp)\n",
    "            current_session_end_time = packet.time\n",
    "\n",
    "            # Check if the packet contains the authentication event pattern\n",
    "            if auth_event_pattern in str(packet.payload):\n",
    "                failed_login_count += 1\n",
    "        else:\n",
    "            # End of session or non-IP packet\n",
    "            if current_session_start_time is not None:\n",
    "                # Calculate session duration\n",
    "                session_duration = current_session_end_time - current_session_start_time\n",
    "\n",
    "                # Append session behavior features to the list\n",
    "                session_behaviour_features.append([session_duration, 1, failed_login_count])\n",
    "\n",
    "                # Calculate interval between authentication attempts\n",
    "                if session_start_time is not None:\n",
    "                    auth_attempt_interval = current_session_start_time - session_start_time\n",
    "                    session_behaviour_features[-1].append(auth_attempt_interval)\n",
    "                else:\n",
    "                    session_behaviour_features[-1].append(None)\n",
    "\n",
    "                # Reset session-related variables for the next session\n",
    "                current_session_start_time = None\n",
    "                current_session_end_time = None\n",
    "                session_start_time = packet.time\n",
    "                failed_login_count = 0\n",
    "\n",
    "    return pd.DataFrame(session_behaviour_features, columns=['session_duration', 'auth_event_count', 'failed_login_count', 'auth_attempt_interval'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HyUJARz8HTe7"
   },
   "source": [
    "**Extract Network Flow Features:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "F2jZe2K-HXFv"
   },
   "outputs": [],
   "source": [
    "def extract_network_flow_features(packets):\n",
    "    network_flow_features = []\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from scapy.all import Ether, IP, TCP, UDP\n",
    "    from datetime import datetime\n",
    "\n",
    "    # Define dictionaries to keep track of flow statistics\n",
    "    flow_packet_counts = {}\n",
    "    flow_total_bytes = {}\n",
    "    flow_first_timestamp = {}\n",
    "    flow_last_timestamp = {}\n",
    "\n",
    "    for packet in packets:\n",
    "        timestamp = datetime.utcfromtimestamp(float(packet.time)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        # Extract Ethernet frame information\n",
    "        if Ether in packet:\n",
    "            eth_src = packet[Ether].src\n",
    "            eth_dst = packet[Ether].dst\n",
    "        else:\n",
    "            eth_src = None\n",
    "            eth_dst = None\n",
    "\n",
    "        # Extract IP packet information\n",
    "        if IP in packet:\n",
    "            src_ip = packet[IP].src\n",
    "            dst_ip = packet[IP].dst\n",
    "\n",
    "            src_port, dst_port = None, None  # Initialize as None by default\n",
    "\n",
    "            if TCP in packet:\n",
    "                src_port = packet[TCP].sport\n",
    "                dst_port = packet[TCP].dport\n",
    "            elif UDP in packet:\n",
    "                src_port = packet[UDP].sport\n",
    "                dst_port = packet[UDP].dport\n",
    "\n",
    "            # Define a flow identifier based on source and destination IP addresses and ports\n",
    "            flow_identifier = (src_ip, dst_ip, src_port, dst_port)\n",
    "\n",
    "            # Update flow statistics\n",
    "            if flow_identifier not in flow_packet_counts:\n",
    "                flow_packet_counts[flow_identifier] = 0\n",
    "                flow_total_bytes[flow_identifier] = 0\n",
    "                flow_first_timestamp[flow_identifier] = timestamp  # Initialize first timestamp\n",
    "\n",
    "            flow_packet_counts[flow_identifier] += 1\n",
    "            flow_total_bytes[flow_identifier] += len(packet)\n",
    "            flow_last_timestamp[flow_identifier] = timestamp  # Update last timestamp\n",
    "\n",
    "    # Extracted network flow features\n",
    "    network_flow_features = []\n",
    "\n",
    "    for flow_identifier, packet_count in flow_packet_counts.items():\n",
    "        src_ip, dst_ip, src_port, dst_port = flow_identifier\n",
    "        total_bytes = flow_total_bytes[flow_identifier]\n",
    "        first_timestamp = flow_first_timestamp[flow_identifier]\n",
    "        last_timestamp = flow_last_timestamp[flow_identifier]\n",
    "\n",
    "        # Determine traffic direction based on source and destination IP addresses\n",
    "        if src_ip.startswith('192.168.1'):  # Example: Check if source IP belongs to your network\n",
    "            traffic_direction = 'Outbound'\n",
    "        elif dst_ip.startswith('192.168.1'):  # Example: Check if destination IP belongs to your network\n",
    "            traffic_direction = 'Inbound'\n",
    "        else:\n",
    "            traffic_direction = 'External'\n",
    "\n",
    "        # Append flow features to the network_flow_features list\n",
    "        network_flow_features.append([src_ip, dst_ip, src_port, dst_port, packet_count, total_bytes, traffic_direction, first_timestamp, last_timestamp])\n",
    "\n",
    "    # Define the column headers\n",
    "    headers = ['src_ip', 'dst_ip', 'src_port', 'dst_port', 'packet_count', 'total_bytes', 'traffic_direction', 'first_timestamp', 'last_timestamp']\n",
    "\n",
    "    return pd.DataFrame(network_flow_features, columns=['src_ip', 'dst_ip', 'src_port', 'dst_port', 'packet_count', 'total_bytes', 'traffic_direction', 'first_timestamp', 'last_timestamp'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bcaW9aX6HZsu"
   },
   "source": [
    "**Extract Protocol-specific Features:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "dLlxoV88Hda6"
   },
   "outputs": [],
   "source": [
    "def extract_protocol_specific_features(packets):\n",
    "    protocol_specific_features = []\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from scapy.all import Ether, IP, TCP, Raw\n",
    "    from datetime import datetime\n",
    "    import re\n",
    "\n",
    "    protocol_specific_features = []\n",
    "\n",
    "    for packet in packets:\n",
    "        # Define a dictionary to store protocol-specific features for this packet\n",
    "        packet_features = {}\n",
    "\n",
    "        # Extract the timestamp of the packet\n",
    "        packet_features['timestamp'] = datetime.utcfromtimestamp(float(packet.time)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        # Extract Ethernet frame information\n",
    "        if Ether in packet:\n",
    "            packet_features['eth_src'] = packet[Ether].src\n",
    "            packet_features['eth_dst'] = packet[Ether].dst\n",
    "\n",
    "        # Extract IP packet information\n",
    "        if IP in packet:\n",
    "            packet_features['src_ip'] = packet[IP].src\n",
    "            packet_features['dst_ip'] = packet[IP].dst\n",
    "            if TCP in packet:\n",
    "                packet_features['src_port'] = packet[TCP].sport\n",
    "                packet_features['dst_port'] = packet[TCP].dport\n",
    "\n",
    "                # Check if the packet is HTTP (port 80)\n",
    "                if packet_features['src_port'] == 80 or packet_features['dst_port'] == 80:\n",
    "                    if Raw in packet:\n",
    "                        http_data = str(packet[Raw].load)\n",
    "\n",
    "                        # Extract HTTP headers (assuming headers are in the first part of the payload)\n",
    "                        http_headers = http_data.split('\\r\\n\\r\\n')[0]\n",
    "                        packet_features['http_headers'] = http_headers\n",
    "\n",
    "                        # Extract HTTP status code (if available)\n",
    "                        status_code_match = re.search(r'HTTP/1.[01] (\\d{3})', http_headers)\n",
    "                        if status_code_match:\n",
    "                            packet_features['http_status_code'] = int(status_code_match.group(1))\n",
    "\n",
    "                # Check if the packet is SSH (port 22)\n",
    "                if packet_features['src_port'] == 22 or packet_features['dst_port'] == 22:\n",
    "                    if Raw in packet:\n",
    "                        ssh_payload = str(packet[Raw].load)\n",
    "                        # Extract SSH protocol details as needed\n",
    "                        packet_features['ssh_protocol_details'] = ssh_payload\n",
    "\n",
    "        # Append the dictionary of features to the list\n",
    "        protocol_specific_features.append(packet_features)\n",
    "\n",
    "    return pd.DataFrame(protocol_specific_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vSl7qc1hHf3A"
   },
   "source": [
    "**Extract Payload Characteristics Features:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "YXdoZIF2Hjpe"
   },
   "outputs": [],
   "source": [
    "def extract_payload_characteristics_features(packets):\n",
    "    payload_characteristics_features = []\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from scapy.all import Ether, IP, TCP, Raw\n",
    "    from datetime import datetime\n",
    "    import string\n",
    "\n",
    "    payload_characteristics_features = []\n",
    "\n",
    "    for packet in packets:\n",
    "        # Define a dictionary to store payload characteristics features for this packet\n",
    "        packet_features = {}\n",
    "\n",
    "        # Extract the timestamp of the packet\n",
    "        packet_features['timestamp'] = datetime.utcfromtimestamp(float(packet.time)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        # Extract Ethernet frame information\n",
    "        if Ether in packet:\n",
    "            packet_features['eth_src'] = packet[Ether].src\n",
    "            packet_features['eth_dst'] = packet[Ether].dst\n",
    "\n",
    "        # Extract IP packet information\n",
    "        if IP in packet:\n",
    "            packet_features['src_ip'] = packet[IP].src\n",
    "            packet_features['dst_ip'] = packet[IP].dst\n",
    "            if TCP in packet:\n",
    "                packet_features['src_port'] = packet[TCP].sport\n",
    "                packet_features['dst_port'] = packet[TCP].dport\n",
    "\n",
    "                # Check if the packet contains payload (Raw layer)\n",
    "                if Raw in packet:\n",
    "                    raw_payload = packet[Raw].load\n",
    "                    packet_features['payload_size'] = len(raw_payload)\n",
    "\n",
    "                    # Clean the payload contents: replace non-printable characters with a placeholder or remove them\n",
    "                    printable = set(string.printable)\n",
    "                    cleaned_payload = ''.join(filter(lambda x: x in printable, raw_payload.decode('utf-8', errors='ignore')))\n",
    "                    packet_features['payload_contents'] = cleaned_payload\n",
    "\n",
    "        # Append the dictionary of features to the list\n",
    "        payload_characteristics_features.append(packet_features)\n",
    "\n",
    "\n",
    "    return pd.DataFrame(payload_characteristics_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**Download the datasets if not present locally:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_dataset(filename, url)   \n",
    "\n",
    "    #if the file is not present locally, let download it!\n",
    "    if os.path.isfile(filename) == False:\n",
    "        print(\"Downloading \"+filename+\" at the url \"+url)\n",
    "        wget.download(url, bar=bar_thermometer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q26AIWBeHmop"
   },
   "source": [
    "**Main Execution and Saving DataFrames:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Ga7-WoxHqU8",
    "outputId": "b9afead5-92c1-4394-a5a1-4b2444e289c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ko\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataset/output_part_1.pcap'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/scapy/utils.py:1209\u001b[0m, in \u001b[0;36mPcapReader_metaclass.open\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1209\u001b[0m     fdesc \u001b[38;5;241m=\u001b[39m \u001b[43mgzip\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: _ByteStream\u001b[39;00m\n\u001b[1;32m   1210\u001b[0m     magic \u001b[38;5;241m=\u001b[39m fdesc\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m4\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/gzip.py:58\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(filename, mode, compresslevel, encoding, errors, newline)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filename, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike)):\n\u001b[0;32m---> 58\u001b[0m     binary_file \u001b[38;5;241m=\u001b[39m \u001b[43mGzipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgz_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompresslevel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwrite\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/gzip.py:174\u001b[0m, in \u001b[0;36mGzipFile.__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fileobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     fileobj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmyfileobj \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset/output_part_1.pcap'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      2\u001b[0m     pcap_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset/output_part_1.pcap\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m     packets \u001b[38;5;241m=\u001b[39m \u001b[43mload_pcap_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpcap_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     network_traffic_df \u001b[38;5;241m=\u001b[39m extract_network_traffic_features(packets)\n\u001b[1;32m      6\u001b[0m     network_traffic_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive/MyDrive/network_traffic_features.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m, in \u001b[0;36mload_pcap_data\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mko\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m packets \u001b[38;5;241m=\u001b[39m \u001b[43mrdpcap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of packets in test load: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(packets)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m packets:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/scapy/utils.py:1144\u001b[0m, in \u001b[0;36mrdpcap\u001b[0;34m(filename, count)\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Read a pcap or pcapng file and return a packet list\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \n\u001b[1;32m   1138\u001b[0m \u001b[38;5;124;03m:param count: read only <count> packets\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;66;03m# Rant: Our complicated use of metaclasses and especially the\u001b[39;00m\n\u001b[1;32m   1141\u001b[0m \u001b[38;5;66;03m# __call__ function is, of course, not supported by MyPy.\u001b[39;00m\n\u001b[1;32m   1142\u001b[0m \u001b[38;5;66;03m# One day we should simplify this mess and use a much simpler\u001b[39;00m\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;66;03m# layout that will actually be supported and properly dissected.\u001b[39;00m\n\u001b[0;32m-> 1144\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mPcapReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fdesc:  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fdesc\u001b[38;5;241m.\u001b[39mread_all(count\u001b[38;5;241m=\u001b[39mcount)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/scapy/utils.py:1179\u001b[0m, in \u001b[0;36mPcapReader_metaclass.__call__\u001b[0;34m(cls, filename)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a cls instance, use the `alternative` if that\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[38;5;124;03mfails.\u001b[39;00m\n\u001b[1;32m   1176\u001b[0m \n\u001b[1;32m   1177\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1178\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__bases__\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m)\n\u001b[0;32m-> 1179\u001b[0m filename, fdesc, magic \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m magic:\n\u001b[1;32m   1181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Scapy_Exception(\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo data could be read!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1183\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/scapy/utils.py:1212\u001b[0m, in \u001b[0;36mPcapReader_metaclass.open\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m   1210\u001b[0m         magic \u001b[38;5;241m=\u001b[39m fdesc\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m   1211\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m:\n\u001b[0;32m-> 1212\u001b[0m         fdesc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1213\u001b[0m         magic \u001b[38;5;241m=\u001b[39m fdesc\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset/output_part_1.pcap'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    pcap_file_path = download_dataset('dataset/output_part_1.pcap', 'http://205.174.165.80/CICDataset/CIC-IDS-2017/Dataset/') \n",
    "    packets = load_pcap_data(pcap_file_path)\n",
    "\n",
    "    network_traffic_df = extract_network_traffic_features(packets)\n",
    "    network_traffic_df.to_csv('/content/drive/MyDrive/network_traffic_features.csv', index=False)\n",
    "\n",
    "    session_behavior_df = extract_session_behavior_features(packets)\n",
    "    session_behavior_df.to_csv('/content/drive/MyDrive/session_behaviour_features.csv', index=False)\n",
    "\n",
    "    network_flow_df = extract_network_flow_features(packets)\n",
    "    network_flow_df.to_csv('/content/drive/MyDrive/network_flow_features.csv', index=False)\n",
    "\n",
    "    protocol_specific_df = extract_protocol_specific_features(packets)\n",
    "    protocol_specific_df.to_csv('/content/drive/MyDrive/protocol_specific_features.csv', index=False)\n",
    "\n",
    "    payload_characteristics_df = extract_payload_characteristics_features(packets)\n",
    "    payload_characteristics_df.to_csv('/content/drive/MyDrive/payload_characteristics_features.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
