{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65SQNsbekm3u"
      },
      "source": [
        "# Create the Fetures Group from PCAPs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cntvSYPZkkUM",
        "outputId": "e217e1fa-824b-4253-bfcf-bdb703f58d91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scapy\n",
            "  Downloading scapy-2.5.0.tar.gz (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: scapy\n",
            "  Building wheel for scapy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scapy: filename=scapy-2.5.0-py2.py3-none-any.whl size=1444330 sha256=03ab9860615424b874fbc96185237a8ca590575a3ee74141e03d1bab56937307\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/b7/03/8344d8cf6695624746311bc0d389e9d05535ca83c35f90241d\n",
            "Successfully built scapy\n",
            "Installing collected packages: scapy\n",
            "Successfully installed scapy-2.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install scapy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvROr7mblQLD",
        "outputId": "b6a3ed51-58aa-46a7-c156-4418c050f317"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of packets in test load: 783877\n",
            "802.3 70:6e:6d:1d:bb:0f > 01:00:0c:cc:cc:cc / LLC / SNAP / Raw\n"
          ]
        }
      ],
      "source": [
        "#load the pcaps\n",
        "from scapy.all import *\n",
        "\n",
        "pcap_file_path = '/content/drive/MyDrive/output_part_1.pcap'\n",
        "packets = rdpcap(pcap_file_path)\n",
        "\n",
        "print(f\"Number of packets in test load: {len(packets)}\")\n",
        "if len(packets) > 0:\n",
        "    print(packets[0].summary())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7bTWTBtLSWG",
        "outputId": "76138123-e9fc-4fb1-ba1c-fd47260435f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "802.3 70:6e:6d:1d:bb:0f > 01:00:0c:cc:cc:cc / LLC / SNAP / Raw\n",
            "802.3 70:6e:6d:1d:bb:06 > 01:00:0c:cc:cc:cc / LLC / SNAP / Raw\n",
            "802.3 70:6e:6d:1d:bb:11 > 01:00:0c:cc:cc:cc / LLC / SNAP / Raw\n",
            "Ether / ARP who has 192.168.10.3 says 192.168.10.50 / Padding\n",
            "Ether / ARP who has 192.168.10.3 says 192.168.10.50 / Padding\n",
            "Ether / ARP is at 18:66:da:9b:e3:7d says 192.168.10.3 / Padding\n",
            "Ether / ARP is at 18:66:da:9b:e3:7d says 192.168.10.3 / Padding\n",
            "802.3 70:6e:6d:1d:bb:02 > 01:00:0c:cc:cc:cc / LLC / SNAP / Raw\n",
            "802.3 70:6e:6d:1d:bb:05 > 01:00:0c:cc:cc:cc / LLC / SNAP / Raw\n",
            "Ether / IP / UDP / DNS Qry \"b'v10.vortex-win.data.microsoft.com.'\" \n"
          ]
        }
      ],
      "source": [
        "for packet in packets[:10]:\n",
        "    print(packet.summary())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yyExVwcFlnVu"
      },
      "outputs": [],
      "source": [
        "#define feature groups\n",
        "\n",
        "network_traffic_features = []\n",
        "authentication_features = []\n",
        "session_behaviour_features = []\n",
        "frequency_features = []\n",
        "network_anomalies_features = []\n",
        "network_flow_features = []\n",
        "protocol_specific_features = []\n",
        "payload_characteristics_features = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nl-DvY5BGDw5"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Features for network traffic:\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "for packet in packets:\n",
        "    # Initialize variables for each feature\n",
        "    eth_src = None\n",
        "    eth_dst = None\n",
        "    src_ip = None\n",
        "    dst_ip = None\n",
        "    src_port = None\n",
        "    dst_port = None\n",
        "    protocol = None\n",
        "    timestamp = packet.time\n",
        "\n",
        "    # Extract Ethernet frame information\n",
        "    if Ether in packet:\n",
        "        eth_src = packet[Ether].src\n",
        "        eth_dst = packet[Ether].dst\n",
        "\n",
        "    # Extract IP packet information\n",
        "    if IP in packet:\n",
        "        src_ip = packet[IP].src\n",
        "        dst_ip = packet[IP].dst\n",
        "\n",
        "        if TCP in packet:\n",
        "            src_port = packet[TCP].sport\n",
        "            dst_port = packet[TCP].dport\n",
        "            protocol = 'TCP'\n",
        "        elif UDP in packet:\n",
        "            src_port = packet[UDP].sport\n",
        "            dst_port = packet[UDP].dport\n",
        "            protocol = 'UDP'\n",
        "        else:\n",
        "            # Handle other IP protocols as needed\n",
        "            protocol = packet[IP].proto\n",
        "\n",
        "    # Append extracted features as a dictionary to the network_traffic_features list\n",
        "    network_traffic_features.append({\n",
        "        'eth_src': eth_src,\n",
        "        'eth_dst': eth_dst,\n",
        "        'src_ip': src_ip,\n",
        "        'dst_ip': dst_ip,\n",
        "        'src_port': src_port,\n",
        "        'dst_port': dst_port,\n",
        "        'protocol': protocol,\n",
        "        'timestamp': timestamp\n",
        "    })\n",
        "\n",
        "# Save the features:\n",
        "\n",
        "# Convert the list of dictionaries to a Pandas DataFrame\n",
        "df = pd.DataFrame(network_traffic_features)\n",
        "\n",
        "# Save the DataFrame as a CSV file\n",
        "df.to_csv('/content/drive/MyDrive/network_traffic_features.csv', index=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlNnlw_51oRr",
        "outputId": "27ba6b8c-8ef9-4179-f59e-59aa801a087d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             timestamp authentication_method failed_login_attempts  \\\n",
            "0  2017-07-06 11:59:17                   UDP                  None   \n",
            "1  2017-07-06 11:59:17                   UDP                  None   \n",
            "2  2017-07-06 11:59:17                   UDP                  None   \n",
            "3  2017-07-06 11:59:17                   UDP                  None   \n",
            "4  2017-07-06 11:59:55                   UDP                  None   \n",
            "\n",
            "   successful_authentication session_duration  \n",
            "0                      False             None  \n",
            "1                      False             None  \n",
            "2                      False             None  \n",
            "3                      False             None  \n",
            "4                      False             None  \n"
          ]
        }
      ],
      "source": [
        "# Authentication features:\n",
        "\n",
        "from scapy.all import TCP, UDP, Raw, rdpcap\n",
        "from datetime import datetime\n",
        "\n",
        "authentication_features = []  # Ensure you have this list defined to store results\n",
        "\n",
        "for packet in packets:\n",
        "    authentication_method = None\n",
        "    failed_login_attempts = None\n",
        "    successful_authentication = None\n",
        "    session_duration = None\n",
        "\n",
        "    payload = None\n",
        "\n",
        "    if packet.haslayer(TCP) and packet[TCP].payload and len(packet[TCP].payload) > 0:\n",
        "        payload = str(packet[TCP].payload)\n",
        "        authentication_method = 'TCP'\n",
        "\n",
        "    elif packet.haslayer(UDP) and packet[UDP].payload and len(packet[UDP].payload) > 0:\n",
        "        payload = str(packet[UDP].payload)\n",
        "        authentication_method = 'UDP'\n",
        "\n",
        "    elif packet.haslayer(Raw) and packet[Raw].payload and len(packet[Raw].payload) > 0:\n",
        "        payload = str(packet[Raw].payload)\n",
        "        authentication_method = 'Raw'\n",
        "\n",
        "    # Extract timestamp from the packet\n",
        "    packet_timestamp = datetime.utcfromtimestamp(float(packet.time)).strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "\n",
        "    # If payload exists, check for patterns\n",
        "    if payload:\n",
        "        # Check for login patterns\n",
        "        if 'login' in payload:\n",
        "            authentication_method += '-Login'\n",
        "        elif 'auth' in payload:\n",
        "            authentication_method += '-Auth'\n",
        "\n",
        "        # Check for failed login attempts - assuming some pattern\n",
        "        if 'failed_attempts=' in payload:\n",
        "            failed_attempts_index = payload.index('failed_attempts=') + len('failed_attempts=')\n",
        "            failed_login_attempts = int(payload[failed_attempts_index:failed_attempts_index+1])\n",
        "\n",
        "        # Check for successful authentication - assuming some pattern\n",
        "        if 'auth=success' in payload:\n",
        "            successful_authentication = True\n",
        "        else:\n",
        "            successful_authentication = False\n",
        "\n",
        "        # For session duration, we'd ideally need timestamps of session start and end, which isn't provided here.\n",
        "        # Placeholder logic for now. You'd need additional parsing to get this.\n",
        "        if 'session_duration=' in payload:\n",
        "            duration_index = payload.index('session_duration=') + len('session_duration=')\n",
        "            session_duration = int(payload[duration_index:duration_index+2])\n",
        "\n",
        "        # Add to our features list\n",
        "        authentication_features.append({\n",
        "            'timestamp': packet_timestamp,\n",
        "            'authentication_method': authentication_method,\n",
        "            'failed_login_attempts': failed_login_attempts,\n",
        "            'successful_authentication': successful_authentication,\n",
        "            'session_duration': session_duration\n",
        "        })\n",
        "\n",
        "df = pd.DataFrame(authentication_features)\n",
        "print(df.head())\n",
        "\n",
        "df.to_csv('/content/drive/MyDrive/authentication_features.csv', index=False)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7OEVrJs1zjn"
      },
      "outputs": [],
      "source": [
        "# Session-related information features:\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from scapy.all import Ether, IP\n",
        "\n",
        "current_session_start_time = None\n",
        "current_session_end_time = None\n",
        "session_start_time = None\n",
        "failed_login_count = 0\n",
        "session_behaviour_features = []\n",
        "session_timestamps = []\n",
        "\n",
        "# Define a pattern to identify authentication-related events\n",
        "auth_event_pattern = \"authentication_failed\"\n",
        "\n",
        "# Iterate through the packets and extract the features\n",
        "for packet in packets:\n",
        "    # Extract Ethernet frame information\n",
        "    if Ether in packet:\n",
        "        eth_src = packet[Ether].src\n",
        "        eth_dst = packet[Ether].dst\n",
        "\n",
        "    # Extract IP packet information\n",
        "    if IP in packet:\n",
        "        # Update session start and end times\n",
        "        if current_session_start_time is None:\n",
        "            current_session_start_time = packet.time\n",
        "            # Convert packet.time to float\n",
        "            timestamp = datetime.utcfromtimestamp(float(packet.time)).strftime('%Y-%m-%d %H:%M:%S')\n",
        "            session_timestamps.append(timestamp)\n",
        "        current_session_end_time = packet.time\n",
        "\n",
        "        # Check if the packet contains the authentication event pattern\n",
        "        if auth_event_pattern in str(packet.payload):\n",
        "            failed_login_count += 1\n",
        "    else:\n",
        "        # End of session or non-IP packet\n",
        "        if current_session_start_time is not None:\n",
        "            # Calculate session duration\n",
        "            session_duration = current_session_end_time - current_session_start_time\n",
        "\n",
        "            # Append session behavior features to the list\n",
        "            session_behaviour_features.append([session_duration, 1, failed_login_count])\n",
        "\n",
        "            # Calculate interval between authentication attempts\n",
        "            if session_start_time is not None:\n",
        "                auth_attempt_interval = current_session_start_time - session_start_time\n",
        "                session_behaviour_features[-1].append(auth_attempt_interval)\n",
        "            else:\n",
        "                session_behaviour_features[-1].append(None)\n",
        "\n",
        "            # Reset session-related variables for the next session\n",
        "            current_session_start_time = None\n",
        "            current_session_end_time = None\n",
        "            session_start_time = packet.time\n",
        "            failed_login_count = 0\n",
        "\n",
        "# Save the features:\n",
        "# Convert the list of lists to a Pandas DataFrame\n",
        "df = pd.DataFrame(session_behaviour_features, columns=['session_duration', 'auth_event_count', 'failed_login_count', 'auth_attempt_interval'])\n",
        "df['session_start_timestamp'] = session_timestamps\n",
        "\n",
        "# Save the DataFrame as a CSV file\n",
        "df.to_csv('/content/drive/MyDrive/session_behaviour_features.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7fI7rn68t6u"
      },
      "outputs": [],
      "source": [
        "# Rate and frequency features:\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "login_attempts = 0\n",
        "successful_logins = 0\n",
        "\n",
        "# Initialize the frequency_features list\n",
        "frequency_features = []\n",
        "\n",
        "# Define a pattern to identify authentication-related events\n",
        "auth_attempt_pattern = \"authentication_attempt\"\n",
        "successful_login_pattern = \"successful_login\"\n",
        "\n",
        "# Iterate through the packets and extract the features\n",
        "for packet in packets:\n",
        "    # Check if the packet contains the authentication attempt pattern\n",
        "    if auth_attempt_pattern in str(packet.payload):\n",
        "        login_attempts += 1\n",
        "    elif successful_login_pattern in str(packet.payload):\n",
        "        successful_logins += 1\n",
        "\n",
        "    # Extract timestamp from the packet\n",
        "    packet_timestamp = datetime.utcfromtimestamp(float(packet.time)).strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "\n",
        "    # Calculate login attempt rate and successful login rate\n",
        "    login_attempt_rate = login_attempts / len(packets)\n",
        "    successful_login_rate = successful_logins / len(packets)\n",
        "\n",
        "    # Append frequency features and timestamp to the list\n",
        "    frequency_features.append([packet_timestamp, login_attempt_rate, successful_login_rate])\n",
        "\n",
        "# Define the column names for the DataFrame\n",
        "column_names = [\"timestamp\", \"login_attempt_rate\", \"successful_login_rate\"]\n",
        "\n",
        "# Save the features:\n",
        "\n",
        "df = pd.DataFrame(frequency_features, columns=column_names)\n",
        "\n",
        "# Save the DataFrame as a CSV file\n",
        "df.to_csv('/content/drive/MyDrive/frequency_features.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9D5JpMm-Gmb"
      },
      "outputs": [],
      "source": [
        "#Network anomaly feature:\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from scapy.all import Ether, IP\n",
        "\n",
        "packet_length_threshold = 1500  # Example threshold, modify as needed\n",
        "network_anomalies_features = []\n",
        "\n",
        "for packet in packets:\n",
        "    # Calculate the length of the packet\n",
        "    packet_length = len(packet)\n",
        "\n",
        "    # Get the timestamp of the packet\n",
        "    packet_timestamp = datetime.utcfromtimestamp(float(packet.time)).strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "    # Determine if the packet is anomalous based on its length\n",
        "    if packet_length > packet_length_threshold:\n",
        "        anomaly_status = 'anomaly_detected'\n",
        "    else:\n",
        "        anomaly_status = 'normal'\n",
        "\n",
        "    # Append features related to this packet to the list\n",
        "    network_anomalies_features.append([packet_timestamp, packet_length, anomaly_status])\n",
        "\n",
        "# Save the features:\n",
        "# Convert the list of lists to a Pandas DataFrame\n",
        "df = pd.DataFrame(network_anomalies_features, columns=['timestamp', 'packet_length', 'status'])\n",
        "\n",
        "# Save the DataFrame as a CSV file\n",
        "df.to_csv('/content/drive/MyDrive/network_anomalies_features.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGhWzO96-lH4"
      },
      "outputs": [],
      "source": [
        "# Network flow features:\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scapy.all import Ether, IP, TCP, UDP\n",
        "from datetime import datetime\n",
        "\n",
        "# Define dictionaries to keep track of flow statistics\n",
        "flow_packet_counts = {}\n",
        "flow_total_bytes = {}\n",
        "flow_first_timestamp = {}\n",
        "flow_last_timestamp = {}\n",
        "\n",
        "for packet in packets:\n",
        "    timestamp = datetime.utcfromtimestamp(float(packet.time)).strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "    # Extract Ethernet frame information\n",
        "    if Ether in packet:\n",
        "        eth_src = packet[Ether].src\n",
        "        eth_dst = packet[Ether].dst\n",
        "    else:\n",
        "        eth_src = None\n",
        "        eth_dst = None\n",
        "\n",
        "    # Extract IP packet information\n",
        "    if IP in packet:\n",
        "        src_ip = packet[IP].src\n",
        "        dst_ip = packet[IP].dst\n",
        "\n",
        "        src_port, dst_port = None, None  # Initialize as None by default\n",
        "\n",
        "        if TCP in packet:\n",
        "            src_port = packet[TCP].sport\n",
        "            dst_port = packet[TCP].dport\n",
        "        elif UDP in packet:\n",
        "            src_port = packet[UDP].sport\n",
        "            dst_port = packet[UDP].dport\n",
        "\n",
        "        # Define a flow identifier based on source and destination IP addresses and ports\n",
        "        flow_identifier = (src_ip, dst_ip, src_port, dst_port)\n",
        "\n",
        "        # Update flow statistics\n",
        "        if flow_identifier not in flow_packet_counts:\n",
        "            flow_packet_counts[flow_identifier] = 0\n",
        "            flow_total_bytes[flow_identifier] = 0\n",
        "            flow_first_timestamp[flow_identifier] = timestamp  # Initialize first timestamp\n",
        "\n",
        "        flow_packet_counts[flow_identifier] += 1\n",
        "        flow_total_bytes[flow_identifier] += len(packet)\n",
        "        flow_last_timestamp[flow_identifier] = timestamp  # Update last timestamp\n",
        "\n",
        "# Extracted network flow features\n",
        "network_flow_features = []\n",
        "\n",
        "for flow_identifier, packet_count in flow_packet_counts.items():\n",
        "    src_ip, dst_ip, src_port, dst_port = flow_identifier\n",
        "    total_bytes = flow_total_bytes[flow_identifier]\n",
        "    first_timestamp = flow_first_timestamp[flow_identifier]\n",
        "    last_timestamp = flow_last_timestamp[flow_identifier]\n",
        "\n",
        "    # Determine traffic direction based on source and destination IP addresses\n",
        "    if src_ip.startswith('192.168.1'):  # Example: Check if source IP belongs to your network\n",
        "        traffic_direction = 'Outbound'\n",
        "    elif dst_ip.startswith('192.168.1'):  # Example: Check if destination IP belongs to your network\n",
        "        traffic_direction = 'Inbound'\n",
        "    else:\n",
        "        traffic_direction = 'External'\n",
        "\n",
        "    # Append flow features to the network_flow_features list\n",
        "    network_flow_features.append([src_ip, dst_ip, src_port, dst_port, packet_count, total_bytes, traffic_direction, first_timestamp, last_timestamp])\n",
        "\n",
        "# Define the column headers\n",
        "headers = ['src_ip', 'dst_ip', 'src_port', 'dst_port', 'packet_count', 'total_bytes', 'traffic_direction', 'first_timestamp', 'last_timestamp']\n",
        "\n",
        "# Save the features:\n",
        "df = pd.DataFrame(network_flow_features, columns=headers)\n",
        "\n",
        "# Save the DataFrame as a CSV file\n",
        "df.to_csv('/content/drive/MyDrive/network_flow_features.csv', index=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pYCY44ny_vzV"
      },
      "outputs": [],
      "source": [
        "# Protocol-specific features:\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scapy.all import Ether, IP, TCP, Raw\n",
        "from datetime import datetime\n",
        "import re\n",
        "\n",
        "protocol_specific_features = []\n",
        "\n",
        "for packet in packets:\n",
        "    # Define a dictionary to store protocol-specific features for this packet\n",
        "    packet_features = {}\n",
        "\n",
        "    # Extract the timestamp of the packet\n",
        "    packet_features['timestamp'] = datetime.utcfromtimestamp(float(packet.time)).strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "    # Extract Ethernet frame information\n",
        "    if Ether in packet:\n",
        "        packet_features['eth_src'] = packet[Ether].src\n",
        "        packet_features['eth_dst'] = packet[Ether].dst\n",
        "\n",
        "    # Extract IP packet information\n",
        "    if IP in packet:\n",
        "        packet_features['src_ip'] = packet[IP].src\n",
        "        packet_features['dst_ip'] = packet[IP].dst\n",
        "        if TCP in packet:\n",
        "            packet_features['src_port'] = packet[TCP].sport\n",
        "            packet_features['dst_port'] = packet[TCP].dport\n",
        "\n",
        "            # Check if the packet is HTTP (port 80)\n",
        "            if packet_features['src_port'] == 80 or packet_features['dst_port'] == 80:\n",
        "                if Raw in packet:\n",
        "                    http_data = str(packet[Raw].load)\n",
        "\n",
        "                    # Extract HTTP headers (assuming headers are in the first part of the payload)\n",
        "                    http_headers = http_data.split('\\r\\n\\r\\n')[0]\n",
        "                    packet_features['http_headers'] = http_headers\n",
        "\n",
        "                    # Extract HTTP status code (if available)\n",
        "                    status_code_match = re.search(r'HTTP/1.[01] (\\d{3})', http_headers)\n",
        "                    if status_code_match:\n",
        "                        packet_features['http_status_code'] = int(status_code_match.group(1))\n",
        "\n",
        "            # Check if the packet is SSH (port 22)\n",
        "            if packet_features['src_port'] == 22 or packet_features['dst_port'] == 22:\n",
        "                if Raw in packet:\n",
        "                    ssh_payload = str(packet[Raw].load)\n",
        "                    # Extract SSH protocol details as needed\n",
        "                    packet_features['ssh_protocol_details'] = ssh_payload\n",
        "\n",
        "    # Append the dictionary of features to the list\n",
        "    protocol_specific_features.append(packet_features)\n",
        "\n",
        "# Save the features:\n",
        "df = pd.DataFrame(protocol_specific_features)\n",
        "\n",
        "# Save the DataFrame as a CSV file\n",
        "df.to_csv('/content/drive/MyDrive/protocol_specific_features.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CsIhEmzAOwu"
      },
      "outputs": [],
      "source": [
        "# Payload characteristics features\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scapy.all import Ether, IP, TCP, Raw\n",
        "from datetime import datetime\n",
        "import string\n",
        "\n",
        "payload_characteristics_features = []\n",
        "\n",
        "for packet in packets:\n",
        "    # Define a dictionary to store payload characteristics features for this packet\n",
        "    packet_features = {}\n",
        "\n",
        "    # Extract the timestamp of the packet\n",
        "    packet_features['timestamp'] = datetime.utcfromtimestamp(float(packet.time)).strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "    # Extract Ethernet frame information\n",
        "    if Ether in packet:\n",
        "        packet_features['eth_src'] = packet[Ether].src\n",
        "        packet_features['eth_dst'] = packet[Ether].dst\n",
        "\n",
        "    # Extract IP packet information\n",
        "    if IP in packet:\n",
        "        packet_features['src_ip'] = packet[IP].src\n",
        "        packet_features['dst_ip'] = packet[IP].dst\n",
        "        if TCP in packet:\n",
        "            packet_features['src_port'] = packet[TCP].sport\n",
        "            packet_features['dst_port'] = packet[TCP].dport\n",
        "\n",
        "            # Check if the packet contains payload (Raw layer)\n",
        "            if Raw in packet:\n",
        "                raw_payload = packet[Raw].load\n",
        "                packet_features['payload_size'] = len(raw_payload)\n",
        "\n",
        "                # Clean the payload contents: replace non-printable characters with a placeholder or remove them\n",
        "                printable = set(string.printable)\n",
        "                cleaned_payload = ''.join(filter(lambda x: x in printable, raw_payload.decode('utf-8', errors='ignore')))\n",
        "                packet_features['payload_contents'] = cleaned_payload\n",
        "\n",
        "    # Append the dictionary of features to the list\n",
        "    payload_characteristics_features.append(packet_features)\n",
        "\n",
        "# Save the features:\n",
        "df = pd.DataFrame(payload_characteristics_features)\n",
        "\n",
        "# Save the DataFrame as a CSV file\n",
        "df.to_csv('/content/drive/MyDrive/payload_characteristics_features.csv', index=False)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}